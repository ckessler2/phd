
import tensorflow as tf
import numpy as np

def LipschitzLoss(x,x_ad,y,y_ad):
    x = tf.cast(x,tf.float32)
    y = tf.expand_dims(y, axis=-1)
    y = tf.cast(y,tf.float32)
    x_ad = tf.cast(x_ad,tf.float32)
    y_ad = tf.cast(y_ad,tf.float32)
    # print(f"x shape = {tf.shape(x)}" )
    # print(f"y shape = {tf.shape(y)}" )
    # print(f"x_ad shape = {tf.shape(x_ad)}" )
    # print(f"y_ad shape = {tf.shape(y_ad)}" )
    
    L = tf.math.divide(tf.math.abs(tf.math.subtract(x, x_ad)), tf.math.abs(tf.math.subtract(y, y_ad)))
    
    return L
    

class TrainingHistory:
    def __init__(self):
        self.history = {
            "loss": [],
            "val_loss": []
        }

    def add_entry(self, loss, val_loss):
        # Ensure data is in the right format
        loss = np.float32(loss)
        val_loss = np.float32(val_loss)
        
        # Append data to respective lists
        self.history["loss"].append(loss)
        self.history["val_loss"].append(val_loss)

class AdversarialTrainer:
    """
    A class for training models with adversarial examples to improve robustness
    against adversarial attacks within an epsilon-ball (L-infinity norm).
    """

    def __init__(self, model, epsilon=0.1):
        """
        Initialises the AdversarialTrainer with a model and a perturbation factor (epsilon).

        Args:
            model (tf.keras.Model): The model to be trained and defended against adversarial attacks.
            epsilon (float): The maximum allowable perturbation for generating adversarial examples.
        """
        self.model = model
        self.epsilon = epsilon

    def generate_adversarial_example(self, x, y):
        """
        Generates an adversarial example for a given input using the Fast Gradient Sign Method (FGSM).

        Args:
            x (tf.Tensor): The input data (features) for which the adversarial example is generated.
            y (tf.Tensor): The true labels corresponding to the input data.

        Returns:
            tf.Tensor: The adversarial example generated by perturbing the input data within the epsilon-ball.
        """
        with tf.GradientTape() as tape:
            tape.watch(x)
            prediction = self.model(x, training=False)
            # Use the MeanSquaredError instance
            loss_fn = tf.keras.losses.MeanSquaredError()
            loss = loss_fn(y, prediction)

        # Calculate the gradient of the loss with respect to the input
        gradient = tape.gradient(loss, x)

        # Extract the sign of the gradient
        signed_grad = tf.sign(gradient)

        # Create the adversarial example by adding a small perturbation within the epsilon-ball
        adversarial_x = x + self.epsilon * signed_grad
        return adversarial_x
        # return tf.clip_by_value(
        #     adversarial_x, 0, 1
        # )  # Ensure values stay within [0, 1] bounds

    def train_with_adversarial_examples(self, train_dataset, epochs=10, callbacks=None, alpha=0.1):
        """
        Trains the model on both normal and adversarial examples to enforce robustness within an epsilon-ball.

        Args:
            train_dataset (tf.data.Dataset): The training dataset providing input-output pairs (x, y).
            epochs (int): The number of epochs for training.
            callbacks (list): A list of callbacks to be invoked during the training process.
                              Defaults to None.

        Returns:
            tf.keras.Model: The trained model after adversarial training.

        Raises:
            ValueError: If the training dataset is not properly formatted.
        """
        if callbacks is None:
            callbacks = []
            
        history2 = TrainingHistory()
        # adversarial_data = []

        for epoch in range(epochs):
            for callback in callbacks:
                callback.on_epoch_begin(epoch)

            for x_batch, y_batch in train_dataset:
                # Generate adversarial examples for the batch within the epsilon-ball
                adversarial_x_batch = self.generate_adversarial_example(
                    x_batch, y_batch
                )
                # adversarial_data.append(np.array(adversarial_x_batch))

                # Concatenate original and adversarial examples
                # combined_x = tf.concat([x_batch, adversarial_x_batch], axis=0)
                # combined_y = tf.concat([y_batch, y_batch], axis=0)

                # Train on combined data
                history = self.model.train_on_batch(x_batch,y_batch)
                loss = np.float32(history[0])
                val_loss = np.float32(history[1])
                
                # history2["history"]["loss"].append(np.float32(history[0]))
                # history2["history"]["val_loss"].append(val_loss)
                history2.add_entry(loss, val_loss)
                
                with tf.GradientTape() as tape:
                    adversarial_y_batch = self.model(adversarial_x_batch, training=True)
                
                    loss = alpha*LipschitzLoss(x_batch, adversarial_x_batch, y_batch, adversarial_y_batch)
                    
                grads = tape.gradient(loss, self.model.trainable_weights)

                tf.keras.optimizers.Adam().apply_gradients(zip(grads, self.model.trainable_weights))

            for callback in callbacks:
                callback.on_epoch_end(epoch)

        print("Adversarial training with epsilon-ball robustness completed.")
        a = np.array(adversarial_x_batch)
        b = np.array(y_batch)
        
        return self.model, history2, np.c_[a,b]

